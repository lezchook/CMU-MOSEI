{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from warnings import simplefilter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Data_Train_modified.csv')\n",
    "data_val = pd.read_csv('Data_Val_modified.csv')\n",
    "data_test = pd.read_csv('Data_Test_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16274/16274 [00:00<00:00, 938294.41it/s]\n",
      "100%|██████████| 1861/1861 [00:00<00:00, 524464.14it/s]\n",
      "100%|██████████| 4662/4662 [00:00<00:00, 1537735.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data_train['sentiment'] = data_train['sentiment'].progress_apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutaral')\n",
    "data_val['sentiment'] = data_val['sentiment'].progress_apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutaral')\n",
    "data_test['sentiment'] = data_test['sentiment'].progress_apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutaral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_count = data_train[data_train[\"sentiment\"] == \"neutaral\"].shape[0]\n",
    "data_positive = data_train[data_train[\"sentiment\"] == \"positive\"]\n",
    "data_negative = data_train[data_train[\"sentiment\"] == \"negative\"]\n",
    "\n",
    "data_positive_downsampled = resample(data_positive, replace=False, n_samples=neutral_count, random_state=42)\n",
    "data_negative_downsampled = resample(data_negative, replace=False, n_samples=neutral_count, random_state=42)\n",
    "data_train = pd.concat([data_train[data_train[\"sentiment\"] == \"neutaral\"], data_positive_downsampled, data_negative_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = \"./Audio/WAV_16000/\"\n",
    "SAMPLE_RATE = 16000\n",
    "HOP_LENGTH = 512\n",
    "N_MFCC= 13\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, start_time, end_time, n_mfcc):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    start_sample = int(start_time * sr)\n",
    "    end_sample = int(end_time * sr)\n",
    "    y_segment = y[start_sample:end_sample]\n",
    "        \n",
    "    mfcc = librosa.feature.mfcc(y=y_segment, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc.T, axis=0)   \n",
    "\n",
    "    return mfcc_mean.flatten()\n",
    "\n",
    "def extract_bert_features(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=600).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mfcc(data, n_mfcc):\n",
    "    data[\"mfcc\"] = data.progress_apply(lambda row: extract_mfcc(os.path.join(audio_folder, row[\"video\"] + \".wav\"), row[\"start_time\"], row[\"end_time\"], N_MFCC), axis=1)\n",
    "    mfcc_columns = [f\"mfcc_{i}\" for i in range(n_mfcc)]\n",
    "    data[mfcc_columns] = pd.DataFrame(data[\"mfcc\"].tolist(), index=data.index)\n",
    "    data.drop(columns=[\"mfcc\"], inplace=True)\n",
    "    return data\n",
    "\n",
    "def add_bert_embedings(data):\n",
    "    simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "    data[\"bert_features\"] = data[\"text\"].progress_apply(lambda x: extract_bert_features(x))\n",
    "    bert_columns = [f\"bert_{i}\" for i in range(768)]\n",
    "    data[bert_columns] = pd.DataFrame(data[\"bert_features\"].tolist(), index=data.index)\n",
    "    data.drop(columns=[\"bert_features\"], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10563/10563 [02:53<00:00, 60.88it/s]\n",
      "100%|██████████| 1861/1861 [00:29<00:00, 63.18it/s]\n",
      "  1%|          | 29/4662 [00:00<00:56, 82.32it/s]d:\\CMU-MOSEI\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n",
      "100%|██████████| 4662/4662 [01:17<00:00, 60.34it/s]\n",
      "100%|██████████| 10563/10563 [02:44<00:00, 64.23it/s]\n",
      "100%|██████████| 1861/1861 [00:27<00:00, 67.75it/s]\n",
      "100%|██████████| 4662/4662 [01:09<00:00, 67.15it/s]\n"
     ]
    }
   ],
   "source": [
    "data_train = add_mfcc(data_train, N_MFCC)\n",
    "data_val = add_mfcc(data_val, N_MFCC)\n",
    "data_test = add_mfcc(data_test, N_MFCC)\n",
    "\n",
    "data_train = add_bert_embedings(data_train)\n",
    "data_val = add_bert_embedings(data_val)\n",
    "data_test = add_bert_embedings(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([data_train, pd.get_dummies(data_train['sentiment'])], axis=1)\n",
    "data_val = pd.concat([data_val, pd.get_dummies(data_val['sentiment'])], axis=1)\n",
    "data_test = pd.concat([data_test, pd.get_dummies(data_test['sentiment'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop(['video', 'start_time', 'end_time', 'sentiment', 'happy', 'sad',\t'anger', 'surprise', 'disgust',\t'fear', 'text', 'ASR', 'negative', 'neutaral', 'positive'], axis=1)\n",
    "y_train = data_train[['negative', 'neutaral', 'positive']]\n",
    "\n",
    "X_val = data_val.drop(['video', 'start_time', 'end_time', 'sentiment', 'happy', 'sad',\t'anger', 'surprise', 'disgust',\t'fear', 'text', 'ASR', 'negative', 'neutaral', 'positive'], axis=1)\n",
    "y_val = data_val[['negative', 'neutaral', 'positive']]\n",
    "\n",
    "X_test = data_test.drop(['video', 'start_time', 'end_time', 'sentiment', 'happy', 'sad',\t'anger', 'surprise', 'disgust',\t'fear', 'text', 'ASR', 'negative', 'neutaral', 'positive'], axis=1)\n",
    "y_test = data_test[['negative', 'neutaral', 'positive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, device):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.targets[index]\n",
    "\n",
    "class DeepNeural(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(2, 2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_shape[1] // 8 * 64, 512)\n",
    "        self.linear2 = nn.Linear(512, 1024)\n",
    "        self.linear3 = nn.Linear(1024, 64)\n",
    "        self.linear4 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.pool2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.pool3(x))\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "trainset = CustomDataset(X_train.to_numpy(), y_train.to_numpy(), device)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "valset = CustomDataset(X_val.to_numpy(), y_val.to_numpy(), device)\n",
    "valloader = DataLoader(valset, batch_size=128, shuffle=False)\n",
    "\n",
    "testset = CustomDataset(X_test.to_numpy(), y_test.to_numpy(), device)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "model = DeepNeural(X_train.shape, y_train.shape[1]).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.0833 , Validation Loss: 1.0310\n",
      "Epoch 2, Training Loss: 1.0037 , Validation Loss: 0.9697\n",
      "Epoch 3, Training Loss: 0.9611 , Validation Loss: 0.9732\n",
      "Epoch 4, Training Loss: 0.9382 , Validation Loss: 0.9300\n",
      "Epoch 5, Training Loss: 0.9263 , Validation Loss: 0.9658\n",
      "Epoch 6, Training Loss: 0.9123 , Validation Loss: 0.9126\n",
      "Epoch 7, Training Loss: 0.9036 , Validation Loss: 0.9015\n",
      "Epoch 8, Training Loss: 0.8968 , Validation Loss: 0.9357\n",
      "Epoch 9, Training Loss: 0.8868 , Validation Loss: 0.9115\n",
      "Epoch 10, Training Loss: 0.8848 , Validation Loss: 0.9556\n",
      "Epoch 11, Training Loss: 0.8774 , Validation Loss: 0.9168\n",
      "Epoch 12, Training Loss: 0.8746 , Validation Loss: 0.9063\n",
      "Epoch 13, Training Loss: 0.8604 , Validation Loss: 0.9079\n",
      "Epoch 14, Training Loss: 0.8578 , Validation Loss: 0.9088\n",
      "Epoch 15, Training Loss: 0.8472 , Validation Loss: 0.9163\n",
      "Epoch 16, Training Loss: 0.8400 , Validation Loss: 0.9059\n",
      "Epoch 17, Training Loss: 0.8320 , Validation Loss: 0.9325\n",
      "Epoch 18, Training Loss: 0.8213 , Validation Loss: 0.9454\n",
      "Epoch 19, Training Loss: 0.8170 , Validation Loss: 0.9357\n",
      "Epoch 20, Training Loss: 0.8171 , Validation Loss: 0.9242\n",
      "Epoch 21, Training Loss: 0.8039 , Validation Loss: 0.9190\n",
      "Epoch 22, Training Loss: 0.7961 , Validation Loss: 0.9287\n",
      "Epoch 23, Training Loss: 0.7896 , Validation Loss: 0.9357\n",
      "Epoch 24, Training Loss: 0.7804 , Validation Loss: 0.9484\n",
      "Epoch 25, Training Loss: 0.7782 , Validation Loss: 0.9154\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        X = X.unsqueeze(1)\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(trainloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            X, y = data\n",
    "            X = X.unsqueeze(1)\n",
    "            output = model(X)\n",
    "            val_loss += loss_function(output, y).item()\n",
    "    \n",
    "    val_loss /= len(valloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss:.4f} , Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6267584585111223\n"
     ]
    }
   ],
   "source": [
    "def evaluate_f1(model, dataloader, device):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем градиенты для экономии памяти\n",
    "        for data in valloader:\n",
    "            X, y = data\n",
    "            X = X.to(device).unsqueeze(1)  # Возможно, потребуется изменить размерность\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            preds = torch.argmax(output, dim=1)  # Получаем предсказанные индексы классов\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())  # Переносим на CPU и в numpy\n",
    "            all_targets.extend(torch.argmax(y, dim=1).cpu().numpy())\n",
    "\n",
    "        \n",
    "        all_preds = np.array(all_preds).flatten()\n",
    "        all_targets = np.array(all_targets).flatten()\n",
    "        f1 = f1_score(all_targets, all_preds, average='weighted')  # Вычисляем F1-score\n",
    "\n",
    "        print(\"F1-score:\", f1)\n",
    "\n",
    "evaluate_f1(model, valloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC 90: F1-score: 0.619552539933813 \\\n",
    "MFCC 80: F1-score: 0.6096668476012584 \\\n",
    "MFCC 70: F1-score: 0.6105239623728058 \\\n",
    "MFCC 60: F1-score: 0.6261661736068509 \\\n",
    "MFCC 50: F1-score: 0.6107048637994825 \\\n",
    "MFCC 40: F1-score: 0.6010986178719756 \\\n",
    "MFCC 30: F1-score: 0.5804465885872316 \\\n",
    "MFCC 20: F1-score: 0.6065589058584931 \\\n",
    "MFCC 13: F1-score: 0.6267584585111223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
